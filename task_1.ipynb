{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 \n",
    "In this task, ConvNext model will be used to perform multi-class classification. First a config file will be created containing the hyperparameters of the experiment. Then a script will be executed to initiate the training process and the model checkpoint will be saved. Finally, ROC curve and AUC score will be calculated. \n",
    "\n",
    "Dataset has been split in the following way:\n",
    "- Train set and val set are obtained from the train directory, a random subset sampler is used to split the data in the train directory in 80:20 ratio\n",
    "- The test set is created from the val directory\n",
    "\n",
    "## Create config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = \"\"\"\n",
    "\n",
    "\n",
    "exp:\n",
    "    data_dir: /media/saitomar/Work/Projects/DeepLense_Test/task_1_dataset/dataset\n",
    "    wandb: False\n",
    "    wandb_api_key: \n",
    "    proj_name: DeepLense\n",
    "    exp_dir: ./runs\n",
    "    exp_name: Task1-ConvNext-0.1\n",
    "    device: auto\n",
    "    log_freq: 20  # steps\n",
    "    log_to_file: False\n",
    "    log_to_stdout: True\n",
    "    val_freq: 1   # epochs\n",
    "    n_workers: 1\n",
    "    pin_memory: True\n",
    "    cache: 2\n",
    "    task: t1\n",
    "entity: saitomar\n",
    "\n",
    "hparams:\n",
    "    restore_ckpt:\n",
    "    seed: 0\n",
    "    batch_size: 16\n",
    "    start_epoch: 0\n",
    "    n_epochs: 2\n",
    "    l_smooth: 0.1\n",
    "    device: auto\n",
    "    num_classes: 3\n",
    "\n",
    "    \n",
    "    model:\n",
    "        type : ConvNext\n",
    "        ConvNext:\n",
    "            in_channels : 1\n",
    "            stem_features : 64\n",
    "            depths : [3, 4, 6]\n",
    "            widths : [256, 512, 1024]\n",
    "            num_classes : 3\n",
    "    optimizer:\n",
    "        opt_type: adamw\n",
    "        opt_kwargs:\n",
    "          lr: 0.005\n",
    "          \n",
    "    \n",
    "    scheduler:\n",
    "        n_warmup: 1\n",
    "        max_epochs: 2\n",
    "        scheduler_type: cosine_annealing\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with open(\"sample_config/config.yaml\", \"w+\") as f:\n",
    "    f.write(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set seed 0\n",
      "Using settings:\n",
      " entity: saitomar\n",
      "exp:\n",
      "  cache: 2\n",
      "  data_dir: /media/saitomar/Work/Projects/DeepLense_Test/task_1_dataset/dataset\n",
      "  device: &id001 !!python/object/apply:torch.device\n",
      "  - cuda\n",
      "  exp_dir: ./runs\n",
      "  exp_name: Task1-ConvNext-0.1\n",
      "  log_freq: 20\n",
      "  log_to_file: false\n",
      "  log_to_stdout: true\n",
      "  n_workers: 1\n",
      "  pin_memory: true\n",
      "  proj_name: DeepLense\n",
      "  save_dir: ./runs/Task1-ConvNext-0.1\n",
      "  task: t1\n",
      "  val_freq: 1\n",
      "  wandb: false\n",
      "  wandb_api_key: null\n",
      "hparams:\n",
      "  batch_size: 16\n",
      "  device: *id001\n",
      "  l_smooth: 0.1\n",
      "  model:\n",
      "    ConvNext:\n",
      "      depths:\n",
      "      - 3\n",
      "      - 4\n",
      "      - 6\n",
      "      in_channels: 1\n",
      "      num_classes: 3\n",
      "      stem_features: 64\n",
      "      widths:\n",
      "      - 256\n",
      "      - 512\n",
      "      - 1024\n",
      "    type: ConvNext\n",
      "  n_epochs: 2\n",
      "  num_classes: 3\n",
      "  optimizer:\n",
      "    opt_kwargs:\n",
      "      lr: 0.005\n",
      "    opt_type: adamw\n",
      "  restore_ckpt: null\n",
      "  scheduler:\n",
      "    max_epochs: 2\n",
      "    n_warmup: 1\n",
      "    scheduler_type: cosine_annealing\n",
      "  seed: 0\n",
      "  start_epoch: 0\n",
      "\n",
      "Created model with 63500611 parameters.\n",
      "Initiating training.\n",
      "Traceback (most recent call last):\n",
      "  File \"pipeline.py\", line 182, in <module>\n",
      "    main(args)\n",
      "  File \"pipeline.py\", line 172, in main\n",
      "    training_pipeline(config)\n",
      "  File \"pipeline.py\", line 120, in training_pipeline\n",
      "    train(model, optimizer, criterion, trainloader, valloader, schedulers, config)\n",
      "  File \"/media/saitomar/Work/Projects/DeepLense_Test/utils/train.py\", line 117, in train\n",
      "    loss, corr = train_single_batch(\n",
      "  File \"/media/saitomar/Work/Projects/DeepLense_Test/utils/train.py\", line 35, in train_single_batch\n",
      "    outputs = net(data)\n",
      "  File \"/home/saitomar/miniconda3/envs/unleashing/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/saitomar/miniconda3/envs/unleashing/lib/python3.8/site-packages/torch/nn/modules/container.py\", line 117, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/saitomar/miniconda3/envs/unleashing/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/media/saitomar/Work/Projects/DeepLense_Test/models/convnext.py\", line 140, in forward\n",
      "    x = self.stem(x)\n",
      "  File \"/home/saitomar/miniconda3/envs/unleashing/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/saitomar/miniconda3/envs/unleashing/lib/python3.8/site-packages/torch/nn/modules/container.py\", line 117, in forward\n",
      "    input = module(input)\n",
      "  File \"/home/saitomar/miniconda3/envs/unleashing/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 727, in _call_impl\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/saitomar/miniconda3/envs/unleashing/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 423, in forward\n",
      "    return self._conv_forward(input, self.weight)\n",
      "  File \"/home/saitomar/miniconda3/envs/unleashing/lib/python3.8/site-packages/torch/nn/modules/conv.py\", line 419, in _conv_forward\n",
      "    return F.conv2d(input, weight, self.bias, self.stride,\n",
      "RuntimeError: Input type (torch.cuda.DoubleTensor) and weight type (torch.cuda.FloatTensor) should be the same\n"
     ]
    }
   ],
   "source": [
    "!python3 pipeline.py --conf sample_config/config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unleashing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
